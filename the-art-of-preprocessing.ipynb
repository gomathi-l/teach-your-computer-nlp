{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Key Components of an NLP Pipeline:**"
      ],
      "metadata": {
        "id": "KX3OZvptxkHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***This notebook demonstrates how to implement key components of an NLP pipeline using spaCy and NLTK.***"
      ],
      "metadata": {
        "id": "4Bo__JJgUoZj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Sample Input: \"I watched Amy playing badminton at the country club yesterday.\"*"
      ],
      "metadata": {
        "id": "nbNLfkXcyAb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Normalization:** Transforming text into a consistent, standard format, such as converting to lowercase, removing punctuation, or expanding abbreviations.\n",
        "\n",
        "Sample Output: [\"i watched amy playing badminton at the country club yesterday\"]"
      ],
      "metadata": {
        "id": "nSm5GxMW37C2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization:** Segmenting text into words, punctuations marks etc.\n",
        "\n",
        "*Sample Output: [\"I\", \"watched\", \"Amy\", \"playing\", \"badminton\", \"at\", \"the\", \"country\", \"club\", \"yesterday\", \".\"]*"
      ],
      "metadata": {
        "id": "6RqLKOpEvJ2_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parts-ofspeech (POS) Tagging:** Assigning word types to tokens, like verb or noun.\n",
        "\n",
        "*Sample Output: [PRON, VERB, PROPN, VERB, NOUN, ADP, DET, ADJ, NOUN, NOUN, PUNCT]*"
      ],
      "metadata": {
        "id": "ryeQoZdMx43x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dependency Parsing:** Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.\n",
        "\n",
        "*Sample Output: \"watched\" - main verb, \"I\" - subject, \"Amy\" - object, etc.*"
      ],
      "metadata": {
        "id": "-pv_7bdvx6Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Named Entity Recognition (NER):** Labelling named “real-world” objects, like persons, companies or locations.\n",
        "\n",
        "*Sample Output: \"Amy\" - PERSON, \"country club\" - LOCATION, \"yesterday\" - DATE.*"
      ],
      "metadata": {
        "id": "zUT-6EPiyIzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatization:** Assigning the base forms of words.\n",
        "\n",
        "*Sample Output: [\"I\", \"watch\", \"Amy\", \"play\", \"badminton\", \"at\", \"the\", \"country\", \"club\", \"yesterday\", \".\"]*"
      ],
      "metadata": {
        "id": "znBUk09-yoVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **SpaCy**"
      ],
      "metadata": {
        "id": "yHSuLGqZlg_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://spacy.io/usage/spacy-101"
      ],
      "metadata": {
        "id": "ZfmleJIPxn7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShQtNhFL-hJr",
        "outputId": "7305bba0-61a7-4847-a31f-8b415f0799d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: spacy\n",
            "Version: 3.7.6\n",
            "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
            "Home-page: https://spacy.io\n",
            "Author: Explosion\n",
            "Author-email: contact@explosion.ai\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: catalogue, cymem, jinja2, langcodes, murmurhash, numpy, packaging, preshed, pydantic, requests, setuptools, spacy-legacy, spacy-loggers, srsly, thinc, tqdm, typer, wasabi, weasel\n",
            "Required-by: en-core-web-sm, fastai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Linguistic Annotations**"
      ],
      "metadata": {
        "id": "baz0R7F2CT7h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://spacy.io/usage/spacy-101#annotations"
      ],
      "metadata": {
        "id": "HGC_2m4HzB2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "SpaCy offers a range of linguistic annotations to help us understand a text's grammatical structure, including word types (such as parts of speech) and the relationships between words (dependency labels)."
      ],
      "metadata": {
        "id": "KWeO9uSNzQAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load small pre-trained English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process text\n",
        "doc = nlp(\"Jake lives on a beach in Italy and buys a popsicle for $10.\")\n",
        "\n",
        "# Print token info\n",
        "for token in doc:\n",
        "    print(\"Token:\", token.text)\n",
        "    print(\"POS:\", token.pos_)\n",
        "    print(\"Dep:\", token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6mjenXx-wjO",
        "outputId": "a3c09455-f373-44a6-d022-1ebb4930774a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Jake\n",
            "POS: ADJ\n",
            "Dep: nsubj\n",
            "Token: lives\n",
            "POS: VERB\n",
            "Dep: ROOT\n",
            "Token: on\n",
            "POS: ADP\n",
            "Dep: prep\n",
            "Token: a\n",
            "POS: DET\n",
            "Dep: det\n",
            "Token: beach\n",
            "POS: NOUN\n",
            "Dep: pobj\n",
            "Token: in\n",
            "POS: ADP\n",
            "Dep: prep\n",
            "Token: Italy\n",
            "POS: PROPN\n",
            "Dep: pobj\n",
            "Token: and\n",
            "POS: CCONJ\n",
            "Dep: cc\n",
            "Token: buys\n",
            "POS: VERB\n",
            "Dep: conj\n",
            "Token: a\n",
            "POS: DET\n",
            "Dep: det\n",
            "Token: popsicle\n",
            "POS: NOUN\n",
            "Dep: dobj\n",
            "Token: for\n",
            "POS: ADP\n",
            "Dep: prep\n",
            "Token: $\n",
            "POS: SYM\n",
            "Dep: nmod\n",
            "Token: 10\n",
            "POS: NUM\n",
            "Dep: pobj\n",
            "Token: .\n",
            "POS: PUNCT\n",
            "Dep: punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note: SpaCy preserves the original text, including character positions (offsets), spaces, and formatting, even after splitting it into tokens, allowing you to reconstruct the text exactly as it was before processing.*"
      ],
      "metadata": {
        "id": "6mfOfFZ8C_5C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "jtXL3ybpD3-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization is the process of breaking down text into smaller meaningful components, such as words, punctuation marks, and other characters, known as tokens."
      ],
      "metadata": {
        "id": "dxn8zlt0D68X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The input text is split into tokens based on whitespace characters (similar to text.split(' ') in Python).\n",
        "- SpaCy has a set of predefined rules called tokenizer exceptions. These rules determine how certain substrings should be tokenized.\n",
        "\n",
        "Example: \"don't\" should be split into two tokens - \"do\" and \"n't\"; \"U.K.\" should remain a single token.\n",
        "\n",
        "- SpaCy processes text from left to right, applying tokenizer exceptions and checking for prefixes (e.g., the quotation mark in \"Hey\"), suffixes (e.g., the period in \"Dr.\"), and infixes (e.g., the hyphen in \"self-help\"). If a rule matches, the tokenizer splits the token accordingly and continues processing the resulting substrings.\n"
      ],
      "metadata": {
        "id": "4SFRPmnCFNCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load small pre-trained English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Tokenize text\n",
        "doc = nlp(\"Jake lives on a beach in Italy and buys a popsicle for $10.\")\n",
        "\n",
        "# Print tokens\n",
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEqI339D-30m",
        "outputId": "f11cd852-acf8-4afe-cafe-6fcc7110b4d3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jake\n",
            "lives\n",
            "on\n",
            "a\n",
            "beach\n",
            "in\n",
            "Italy\n",
            "and\n",
            "buys\n",
            "a\n",
            "popsicle\n",
            "for\n",
            "$\n",
            "10\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part-of-speech Tags and Dependencies**"
      ],
      "metadata": {
        "id": "KZ4tHLsypK0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SpaCy a pre-trained pipeline consisting of statistical models trained on large datasets. These models help us predict the most likely POS tags, dependency labels, and other attributes for each token.\n",
        "\n",
        "**Parts-of-Speech Tagging:**\n",
        "Classifies each word in a sentence as a noun, verb, adjective, etc. SpaCy utilizes both simple UPOS tags (universal part-of-speech) and more detailed tags.\n",
        "\n",
        "**Syntactic Dependencies:**\n",
        "Describe the relationships between tokens in a sentence, identifying which token is the subject, object, or modifier of another token."
      ],
      "metadata": {
        "id": "YqiJBg-ZppWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the spaCy package\n",
        "import spacy\n",
        "\n",
        "# Load the small pre-trained English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Parse and tag the text\n",
        "doc = nlp(\"Jake lives on a beach in Italy and buys a popsicle for $10.\")\n",
        "\n",
        "# Print various attributes of each token:\n",
        "    # token.text: Original word text\n",
        "    # token.lemma_: Base form of the word (lemma)\n",
        "    # token.pos_: Universal part-of-speech tag\n",
        "    # token.tag_: Detailed part-of-speech tag\n",
        "    # token.dep_: Syntactic dependency label\n",
        "    # token.shape_: Word shape – capitalization, punctuation, digits, etc\n",
        "    # token.is_alpha: Whether the token consists of alphabetic characters\n",
        "    # token.is_stop: Whether the token is a stop word (common words that are often filtered out)\n",
        "for token in doc:\n",
        "    print(f\"Token: {token.text:12} | Lemma: {token.lemma_:12} | POS: {token.pos_:6} | \"\n",
        "          f\"Tag: {token.tag_:6} | Dep: {token.dep_:8} | Shape: {token.shape_:8} | \"\n",
        "          f\"Alpha: {str(token.is_alpha):5} | Stop: {str(token.is_stop):5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nG7LzPrE1p6",
        "outputId": "0eca17d8-19e9-4662-ddbd-8f301555f47c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Jake         | Lemma: jake         | POS: ADJ    | Tag: JJ     | Dep: nsubj    | Shape: Xxxx     | Alpha: True  | Stop: False\n",
            "Token: lives        | Lemma: live         | POS: VERB   | Tag: VBZ    | Dep: ROOT     | Shape: xxxx     | Alpha: True  | Stop: False\n",
            "Token: on           | Lemma: on           | POS: ADP    | Tag: IN     | Dep: prep     | Shape: xx       | Alpha: True  | Stop: True \n",
            "Token: a            | Lemma: a            | POS: DET    | Tag: DT     | Dep: det      | Shape: x        | Alpha: True  | Stop: True \n",
            "Token: beach        | Lemma: beach        | POS: NOUN   | Tag: NN     | Dep: pobj     | Shape: xxxx     | Alpha: True  | Stop: False\n",
            "Token: in           | Lemma: in           | POS: ADP    | Tag: IN     | Dep: prep     | Shape: xx       | Alpha: True  | Stop: True \n",
            "Token: Italy        | Lemma: Italy        | POS: PROPN  | Tag: NNP    | Dep: pobj     | Shape: Xxxxx    | Alpha: True  | Stop: False\n",
            "Token: and          | Lemma: and          | POS: CCONJ  | Tag: CC     | Dep: cc       | Shape: xxx      | Alpha: True  | Stop: True \n",
            "Token: buys         | Lemma: buy          | POS: VERB   | Tag: VBZ    | Dep: conj     | Shape: xxxx     | Alpha: True  | Stop: False\n",
            "Token: a            | Lemma: a            | POS: DET    | Tag: DT     | Dep: det      | Shape: x        | Alpha: True  | Stop: True \n",
            "Token: popsicle     | Lemma: popsicle     | POS: NOUN   | Tag: NN     | Dep: dobj     | Shape: xxxx     | Alpha: True  | Stop: False\n",
            "Token: for          | Lemma: for          | POS: ADP    | Tag: IN     | Dep: prep     | Shape: xxx      | Alpha: True  | Stop: True \n",
            "Token: $            | Lemma: $            | POS: SYM    | Tag: $      | Dep: nmod     | Shape: $        | Alpha: False | Stop: False\n",
            "Token: 10           | Lemma: 10           | POS: NUM    | Tag: CD     | Dep: pobj     | Shape: dd       | Alpha: False | Stop: False\n",
            "Token: .            | Lemma: .            | POS: PUNCT  | Tag: .      | Dep: punct    | Shape: .        | Alpha: False | Stop: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize dependencies\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"dep\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "GqGUY6XEnbH5",
        "outputId": "1a9f5b35-d364-4d44-88aa-89f3727ca37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f07fddc6523e4749a01ba8ebc66647a7-0\" class=\"displacy\" width=\"2500\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Jake</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">lives</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">on</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">beach</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Italy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">buys</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">popsicle</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">10.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M385.0,354.0 L393.0,342.0 377.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-2\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,354.0 L587,342.0 603,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,354.0 L748.0,342.0 732.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-5\" stroke-width=\"2px\" d=\"M945,352.0 C945,264.5 1085.0,264.5 1085.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1085.0,354.0 L1093.0,342.0 1077.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-6\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1270.0,354.0 L1278.0,342.0 1262.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-7\" stroke-width=\"2px\" d=\"M245,352.0 C245,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-9\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,177.0 1790.0,177.0 1790.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1790.0,354.0 L1798.0,342.0 1782.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-10\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,89.5 1970.0,89.5 1970.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,354.0 L1978.0,342.0 1962.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-11\" stroke-width=\"2px\" d=\"M2170,352.0 C2170,264.5 2310.0,264.5 2310.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2170,354.0 L2162,342.0 2178,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-f07fddc6523e4749a01ba8ebc66647a7-0-12\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,177.0 2315.0,177.0 2315.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-f07fddc6523e4749a01ba8ebc66647a7-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2315.0,354.0 L2323.0,342.0 2307.0,342.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note: SpaCy provides a spacy.explain() function to explain the meaning of tags and labels.*"
      ],
      "metadata": {
        "id": "B5EeMIF0rQ83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the spacy.explain function to understand the label\n",
        "spacy.explain(\"NNP\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QE57U1aWuSO8",
        "outputId": "ba0bc823-f49e-4ef3-bc83-2b9ee750b69a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'noun, proper singular'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Named Entities**"
      ],
      "metadata": {
        "id": "EhYfTanEuU4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load small pre-trained English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process text\n",
        "doc = nlp(\"Jake lives on a beach in Italy and buys a popsicle for $10.\")\n",
        "\n",
        "# Print named entities\n",
        "for ent in doc.ents:\n",
        "    print(f\"Text: {ent.text} | Start: {ent.start_char} | End: {ent.end_char} | Label: {ent.label_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1iFQf5yhZuD",
        "outputId": "6e19609a-d1a2-462e-a273-4e7e4d5c2fad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Jake | Start: 0 | End: 4 | Label: NORP\n",
            "Text: Italy | Start: 25 | End: 30 | Label: GPE\n",
            "Text: 10 | Start: 56 | End: 58 | Label: MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the spacy.explain function to understand the label\n",
        "spacy.explain(\"GPE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Qiu35aDguHWV",
        "outputId": "4dec713a-e51c-4dc3-f71e-b7ca8f1865df"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Countries, cities, states'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize named entities\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "hr0NRWIws79h",
        "outputId": "1310adf8-2dc6-4791-ea33-10e7959b6582"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Jake\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
              "</mark>\n",
              " lives on a beach in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Italy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and buys a popsicle for $\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    10\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NLTK**"
      ],
      "metadata": {
        "id": "XjV3px3NleAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: https://www.nltk.org/"
      ],
      "metadata": {
        "id": "75V_HPvRlbnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tokenization**"
      ],
      "metadata": {
        "id": "BWGV3QNNk_OO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download 'punkt' - a pre-trained model provided by nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Tokenize the input text\n",
        "text = \"Jake lives on a beach in Italy and buys a popsicle for $10.\"\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Print each token\n",
        "for token in tokens:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTHybZPaNpE-",
        "outputId": "80b69a5c-0a7b-40c5-f2e8-b85086b71ceb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jake\n",
            "lives\n",
            "on\n",
            "a\n",
            "beach\n",
            "in\n",
            "Italy\n",
            "and\n",
            "buys\n",
            "a\n",
            "popsicle\n",
            "for\n",
            "$\n",
            "10\n",
            ".\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lemmatization and Parts-of-speech Tags**"
      ],
      "metadata": {
        "id": "N1NP3MDZk3Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the required NLTK data resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet, stopwords\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "# Converts NLTK POS tags to WordNet POS tags\n",
        "# WordNet recognizes adjectives, verbs, nouns, and adverbs\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'): # adjectives\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'): # verbs\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'): # nouns\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'): # adverbs\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Lemmatize function using WordNet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "text = \"Jake lives on a beach in Italy and buys a popsicle for $10.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# POS tagging\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Define stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Loop through each token and print various attributes of each token\n",
        "for token, pos_tag in tagged_tokens:\n",
        "    lemma = lemmatizer.lemmatize(token, get_wordnet_pos(pos_tag)) if get_wordnet_pos(pos_tag) else token\n",
        "    # Check if only consists only of alphabetic characters\n",
        "    is_alpha = token.isalpha()\n",
        "    # Check for stop words\n",
        "    is_stop = token.lower() in stop_words\n",
        "    shape = ''.join(['X' if char.isupper() else 'x' if char.islower() else 'd' if char.isdigit() else char for char in token])\n",
        "\n",
        "    print(f\"Token: {token:12} | Lemma: {lemma:12} | POS: {pos_tag:6} | Shape: {shape:8} | Alpha: {str(is_alpha):5} | Stop: {str(is_stop):5}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4DhQV-tOC-Y",
        "outputId": "9bdc3081-2806-46f1-feb4-2b4c1b5f73cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: Jake         | Lemma: Jake         | POS: NNP    | Shape: Xxxx     | Alpha: True  | Stop: False\n",
            "Token: lives        | Lemma: live         | POS: VBZ    | Shape: xxxxx    | Alpha: True  | Stop: False\n",
            "Token: on           | Lemma: on           | POS: IN     | Shape: xx       | Alpha: True  | Stop: True \n",
            "Token: a            | Lemma: a            | POS: DT     | Shape: x        | Alpha: True  | Stop: True \n",
            "Token: beach        | Lemma: beach        | POS: NN     | Shape: xxxxx    | Alpha: True  | Stop: False\n",
            "Token: in           | Lemma: in           | POS: IN     | Shape: xx       | Alpha: True  | Stop: True \n",
            "Token: Italy        | Lemma: Italy        | POS: NNP    | Shape: Xxxxx    | Alpha: True  | Stop: False\n",
            "Token: and          | Lemma: and          | POS: CC     | Shape: xxx      | Alpha: True  | Stop: True \n",
            "Token: buys         | Lemma: buy          | POS: VBZ    | Shape: xxxx     | Alpha: True  | Stop: False\n",
            "Token: a            | Lemma: a            | POS: DT     | Shape: x        | Alpha: True  | Stop: True \n",
            "Token: popsicle     | Lemma: popsicle     | POS: NN     | Shape: xxxxxxxx | Alpha: True  | Stop: False\n",
            "Token: for          | Lemma: for          | POS: IN     | Shape: xxx      | Alpha: True  | Stop: True \n",
            "Token: $            | Lemma: $            | POS: $      | Shape: $        | Alpha: False | Stop: False\n",
            "Token: 10           | Lemma: 10           | POS: CD     | Shape: dd       | Alpha: False | Stop: False\n",
            "Token: .            | Lemma: .            | POS: .      | Shape: .        | Alpha: False | Stop: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entity Recognition**"
      ],
      "metadata": {
        "id": "xIA5N8ZFlB_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the required NLTK data resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker_tab')\n",
        "\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag, ne_chunk\n",
        "\n",
        "text = \"Jake lives on a beach in Italy and buys a popsicle for $10.\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Process the text\n",
        "ner_tree = ne_chunk(tagged_tokens)\n",
        "\n",
        "# Print the entities\n",
        "for chunk in ner_tree:\n",
        "    if hasattr(chunk, 'label'):  # This checks if the chunk is a named entity\n",
        "        entity = \" \".join([token for token, pos in chunk])  # Concatenate tokens in the named entity\n",
        "        label = chunk.label()  # Get the entity label (e.g., PERSON, GPE)\n",
        "        print(f\"Text: {entity} | Label: {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYd38f2hgpnG",
        "outputId": "cc0b353c-dde1-45f1-c055-1333ec2c67d9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Jake | Label: GPE\n",
            "Text: Italy | Label: GPE\n"
          ]
        }
      ]
    }
  ]
}
